{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GestureDetection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JOVkCDjMQA1G",
        "outputId": "4dda1825-f473-46d9-9ee2-03d62b0a27fb"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcDzW1hVRy_J"
      },
      "source": [
        "import numpy as np\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "import cv2"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOw7-fgWTDIk"
      },
      "source": [
        "def get_model():\r\n",
        "    # Create a simple model.\r\n",
        "    inputs = keras.Input(shape=(32,))\r\n",
        "    outputs = keras.layers.Dense(1)(inputs)\r\n",
        "    model = keras.Model(inputs, outputs)\r\n",
        "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\r\n",
        "    return model"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooUfoALSTEQF"
      },
      "source": [
        "##model = get_model()\r\n",
        "##model = keras.Sequential([keras.Input((32,)), keras.layers.Dense(1)])\r\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi9G50gd5BeF",
        "outputId": "5791be18-9979-4b32-cfff-be28b43524de"
      },
      "source": [
        "model = keras.models.Sequential()\r\n",
        "\r\n",
        "model.add(keras.layers.InputLayer(\r\n",
        "    input_shape=(128, 128, 3)\r\n",
        "))\r\n",
        "\r\n",
        "model.add(\r\n",
        "    keras.layers.Conv2D(\r\n",
        "        filters=32,\r\n",
        "        kernel_size=(5,5),\r\n",
        "        strides = (1,1),\r\n",
        "        padding='same',\r\n",
        "        activation='relu',\r\n",
        "        name='Conv_1'))\r\n",
        "\r\n",
        "model.add(\r\n",
        "    keras.layers.MaxPool2D(\r\n",
        "        pool_size = (2,2),\r\n",
        "        name = 'Pool_1'))#Image_size: 32*64*64(32 filters,image_size 64*64)\r\n",
        "\r\n",
        "model.add(\r\n",
        "    keras.layers.Conv2D(\r\n",
        "        filters = 64,\r\n",
        "        kernel_size = (5,5),\r\n",
        "        strides = (1,1),\r\n",
        "        padding = 'same',\r\n",
        "        activation = 'relu',\r\n",
        "        name = 'Conv_2'))\r\n",
        "\r\n",
        "model.add(\r\n",
        "    keras.layers.MaxPool2D(\r\n",
        "        pool_size = (2,2),\r\n",
        "        name = 'Pool_2'))#Image_size: 64*32*32(64 filters,image_size 32*32)\r\n",
        "\r\n",
        "model.add(\r\n",
        "    keras.layers.Conv2D(\r\n",
        "        filters = 128,\r\n",
        "        kernel_size = (5,5),\r\n",
        "        strides = (1,1),\r\n",
        "        padding = 'same',\r\n",
        "        activation = 'relu',\r\n",
        "        name = 'Conv_3'))\r\n",
        "\r\n",
        "model.add(\r\n",
        "    keras.layers.MaxPool2D(\r\n",
        "        pool_size = (2,2),\r\n",
        "        name = 'Pool_3'))#Image_size: 128*16*16(128 filters,image_size 16*16)\r\n",
        "\r\n",
        "model.add(\r\n",
        "    keras.layers.Conv2D(\r\n",
        "        filters = 256,\r\n",
        "        kernel_size = (5,5),\r\n",
        "        strides = (1,1),\r\n",
        "        padding = 'same',\r\n",
        "        activation = 'relu',\r\n",
        "        name = 'Conv_4'))\r\n",
        "\r\n",
        "model.add(\r\n",
        "    keras.layers.MaxPool2D(\r\n",
        "        pool_size = (2,2),\r\n",
        "        name = 'Pool_4'))#Image_size: 256*8*8(256 filters,image_size 8*8)\r\n",
        "\r\n",
        "model.add(keras.layers.Flatten())\r\n",
        "model.add(keras.layers.Dense(units=1024, activation='relu',name = 'fc_1'))\r\n",
        "model.add(keras.layers.Dropout(rate=0.2))\r\n",
        "model.add(keras.layers.Dense(units=512, activation='relu',name = 'fc_2'))\r\n",
        "model.add(keras.layers.Dense(units=10,activation='softmax',name = 'fc_3'))\r\n",
        "model.save('/tmp/model')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG4-UEiTSId7"
      },
      "source": [
        " model.built = True\r\n",
        "model.load_weights(\"/content/Train_weights_1.h5\");"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nADLejdH5jKA"
      },
      "source": [
        "Now we have the same model, ready to test on our own input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAmxZ-UH6ZKA"
      },
      "source": [
        "img_cv = cv2.imread(\"/content/img_6.jpg\")\r\n",
        "img_cv_r = cv2.resize(img_cv,(128,128)) # testing purposes only"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb-jedPY-TrT"
      },
      "source": [
        "# function that takes path to the image- and above lines\r\n",
        "# c0- safe driving\r\n",
        "# c1- texting\r\n",
        "# c2- talking on phone\r\n",
        "# c3- operating center console\r\n",
        "# c4- drinking\r\n",
        "# c5- reaching behind\r\n",
        "# c6- hair/makeup\r\n",
        "# c7- talking to passenger \r\n",
        "def outputLabel (predict):\r\n",
        "    if (predict == 1 | predict == 3) :\r\n",
        "      return 1\r\n",
        "    if ((predict == 2 | predict == 4)) :\r\n",
        "      return 2\r\n",
        "    return (predict - 2)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxSGqqvX7L4q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a249f2a-b982-4b92-81d2-913776b1921e"
      },
      "source": [
        "img_cv = cv2.imread(\"/content/img_6.jpg\")\r\n",
        "img_cv_r = cv2.resize(img_cv,(128,128))\r\n",
        "img_cv_predict = np.reshape(img_cv_r,[1,128,128,3]) # 128 by 128 dimension, 3 because 3 channel rgb for color\r\n",
        "arr_predict = model.predict(img_cv_predict,batch_size = 1)\r\n",
        "\r\n",
        "print(arr_predict)\r\n",
        "print(np.argmax(arr_predict))\r\n",
        "\r\n",
        "#int label = outputLabel(np.argmax(arr_predict))\r\n",
        "\r\n",
        "#print(label)\r\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.4608931e-05 9.9973863e-01 1.1326193e-05 1.9129227e-05 3.8288131e-06\n",
            "  8.9376434e-10 1.6414231e-07 1.9432498e-04 4.9024161e-06 3.0800957e-06]]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF2UkTDL-Oho"
      },
      "source": [
        "# write a function to group together the labels, put the final class in json file to merge"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}